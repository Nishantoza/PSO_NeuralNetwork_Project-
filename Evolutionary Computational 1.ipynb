{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6eeeba0",
   "metadata": {},
   "source": [
    "# Section A: Problem Statement – Enhancing Neural Network Performance with Particle Swarm Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f799fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so,I have Chosen digits dataset from scikit learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4744d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa08a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_63</th>\n",
       "      <th>feature_64</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_56  feature_57  \\\n",
       "0        0.0        0.0        0.0         0.0  ...         0.0         0.0   \n",
       "1        0.0        0.0        0.0         0.0  ...         0.0         0.0   \n",
       "2        0.0        0.0        0.0         0.0  ...         0.0         0.0   \n",
       "3        0.0        0.0        0.0         8.0  ...         0.0         0.0   \n",
       "4        0.0        0.0        0.0         0.0  ...         0.0         0.0   \n",
       "\n",
       "   feature_58  feature_59  feature_60  feature_61  feature_62  feature_63  \\\n",
       "0         0.0         6.0        13.0        10.0         0.0         0.0   \n",
       "1         0.0         0.0        11.0        16.0        10.0         0.0   \n",
       "2         0.0         0.0         3.0        11.0        16.0         9.0   \n",
       "3         0.0         7.0        13.0        13.0         9.0         0.0   \n",
       "4         0.0         0.0         2.0        16.0         4.0         0.0   \n",
       "\n",
       "   feature_64  target  \n",
       "0         0.0       0  \n",
       "1         0.0       1  \n",
       "2         0.0       2  \n",
       "3         0.0       3  \n",
       "4         0.0       4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the digits dataset (MNIST equivalent for digits classification)\n",
    "digits = load_digits()\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "df_digits = pd.DataFrame(digits.data, columns=[f'feature_{i+1}' for i in range(digits.data.shape[1])])\n",
    "df_digits['target'] = digits.target\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df_digits.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8943ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a model building function\n",
    "def build_model(learning_rate=0.001, num_neurons=64, solver='adam'):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(int(num_neurons),),\n",
    "                          learning_rate_init=learning_rate,\n",
    "                          solver=solver,\n",
    "                          max_iter=200,\n",
    "                          random_state=42)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77aa756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters (Random Search): {'learning_rate': 0.01, 'neurons': 32, 'solver': 'adam'}\n",
      "Best Validation Accuracy (Random Search): 0.9826\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Random Search (Traditional Optimization)\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "neurons = [32, 64, 128]\n",
    "solvers = ['adam', 'sgd']\n",
    "\n",
    "best_acc_random = 0\n",
    "best_params_random = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for neuron in neurons:\n",
    "        for solver in solvers:\n",
    "            model = build_model(learning_rate=lr, num_neurons=neuron, solver=solver)\n",
    "            model.fit(x_train, y_train)\n",
    "            val_preds = model.predict(x_val)\n",
    "            val_acc = accuracy_score(y_val, val_preds)\n",
    "\n",
    "            if val_acc > best_acc_random:\n",
    "                best_acc_random = val_acc\n",
    "                best_params_random = {'learning_rate': lr, 'neurons': neuron, 'solver': solver}\n",
    "\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "print(\"\\nBest Parameters (Random Search):\", best_params_random)\n",
    "print(\"Best Validation Accuracy (Random Search): {:.4f}\".format(best_acc_random))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5870c1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'hidden_layer_sizes': (150,), 'learning_rate_init': 0.001}\n",
      "Best Accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],  # Different learning rates to try\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,)]  # Different number of neurons\n",
    "}\n",
    "\n",
    "# Iterate over all parameter combinations\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # Build and train the model\n",
    "    model = MLPClassifier(hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "                          learning_rate_init=params['learning_rate_init'],\n",
    "                          max_iter=200,\n",
    "                          random_state=42)\n",
    "    model.fit(x_train, y_train)  # Train the model\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Update best model if current one is better\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = params\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f2b8498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters (PSO):\n",
      "Learning Rate: 0.00589\n",
      "Neurons: 128\n",
      "Best Validation Accuracy (PSO): 0.9896\n"
     ]
    }
   ],
   "source": [
    "# Step 5: PSO Optimization\n",
    "\n",
    "# Simple PSO (no pyswarm needed!)\n",
    "def objective_function(params):\n",
    "    learning_rate, num_neurons = params\n",
    "    learning_rate = float(learning_rate)\n",
    "    num_neurons = int(num_neurons)\n",
    "    if num_neurons < 10:\n",
    "        num_neurons = 10\n",
    "\n",
    "    model = build_model(learning_rate=learning_rate, num_neurons=num_neurons)\n",
    "    model.fit(x_train, y_train)\n",
    "    val_preds = model.predict(x_val)\n",
    "    val_acc = accuracy_score(y_val, val_preds)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    return -val_acc  # PSO minimizes\n",
    "\n",
    "# Basic PSO algorithm\n",
    "def simple_pso(objective_function, lb, ub, swarmsize=5, maxiter=3):\n",
    "    dim = len(lb)\n",
    "    X = np.random.uniform(low=lb, high=ub, size=(swarmsize, dim))\n",
    "    V = np.zeros((swarmsize, dim))\n",
    "    pbest = X.copy()\n",
    "    pbest_val = np.array([objective_function(x) for x in X])\n",
    "    gbest = pbest[np.argmin(pbest_val)]\n",
    "    gbest_val = np.min(pbest_val)\n",
    "\n",
    "    w = 0.5\n",
    "    c1 = 1\n",
    "    c2 = 2\n",
    "\n",
    "    for it in range(maxiter):\n",
    "        for i in range(swarmsize):\n",
    "            r1, r2 = np.random.rand(dim), np.random.rand(dim)\n",
    "            V[i] = (w * V[i]) + (c1 * r1 * (pbest[i] - X[i])) + (c2 * r2 * (gbest - X[i]))\n",
    "            X[i] = X[i] + V[i]\n",
    "            X[i] = np.clip(X[i], lb, ub)\n",
    "            val = objective_function(X[i])\n",
    "\n",
    "            if val < pbest_val[i]:\n",
    "                pbest[i] = X[i]\n",
    "                pbest_val[i] = val\n",
    "\n",
    "        gbest = pbest[np.argmin(pbest_val)]\n",
    "        gbest_val = np.min(pbest_val)\n",
    "        \n",
    "    return gbest, gbest_val\n",
    "\n",
    "# Define the search space\n",
    "lb = [0.0001, 32]\n",
    "ub = [0.01, 128]\n",
    "\n",
    "best_params_pso, best_score_pso = simple_pso(objective_function, lb, ub, swarmsize=5, maxiter=3)\n",
    "\n",
    "# Extract best parameters\n",
    "best_learning_rate_pso = best_params_pso[0]\n",
    "best_neurons_pso = int(best_params_pso[1])\n",
    "\n",
    "print(\"\\nBest Parameters (PSO):\")\n",
    "print(f\"Learning Rate: {best_learning_rate_pso:.5f}\")\n",
    "print(f\"Neurons: {best_neurons_pso}\")\n",
    "print(f\"Best Validation Accuracy (PSO): {-best_score_pso:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceeebc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy (Random Search): 0.9722\n",
      "Test Accuracy (PSO): 0.9778\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Final Model Training and Evaluation\n",
    "\n",
    "# Train final model from Random Search\n",
    "final_model_random = build_model(\n",
    "    learning_rate=best_params_random['learning_rate'],\n",
    "    num_neurons=best_params_random['neurons'],\n",
    "    solver=best_params_random['solver']\n",
    ")\n",
    "final_model_random.fit(np.vstack((x_train, x_val)), np.hstack((y_train, y_val)))\n",
    "test_preds_random = final_model_random.predict(x_test)\n",
    "test_acc_random = accuracy_score(y_test, test_preds_random)\n",
    "\n",
    "# Train final model from PSO\n",
    "final_model_pso = build_model(\n",
    "    learning_rate=best_learning_rate_pso,\n",
    "    num_neurons=best_neurons_pso\n",
    ")\n",
    "final_model_pso.fit(np.vstack((x_train, x_val)), np.hstack((y_train, y_val)))\n",
    "test_preds_pso = final_model_pso.predict(x_test)\n",
    "test_acc_pso = accuracy_score(y_test, test_preds_pso)\n",
    "\n",
    "print(\"\\nTest Accuracy (Random Search): {:.4f}\".format(test_acc_random))\n",
    "print(\"Test Accuracy (PSO): {:.4f}\".format(test_acc_pso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590e25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion: The PSO-optimized model outperformed the Random Search model.\n"
     ]
    }
   ],
   "source": [
    "if test_acc_pso > test_acc_random:\n",
    "    print(\"\\nConclusion: The PSO-optimized model outperformed the Random Search model.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: The Random Search model performed better, but PSO achieved competitive results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6411ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Random Search vs PSO-Optimized Model:\n",
      "Random Search Test Accuracy: 0.9722\n",
      "PSO-Optimized Test Accuracy: 0.9778\n",
      "\n",
      "McNemar's Test Result:\n",
      "p-value: 0.68750\n",
      "No **statistically significant** improvement from PSO optimization.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# Generate confusion matrix for McNemar's test\n",
    "contingency_table = np.zeros((2, 2))\n",
    "\n",
    "# Compare predictions of Random Search model and PSO model\n",
    "for i in range(len(y_test)):\n",
    "    random_search_correct = (test_preds_random[i] == y_test[i])\n",
    "    pso_correct = (test_preds_pso[i] == y_test[i])\n",
    "    \n",
    "    if random_search_correct and pso_correct:\n",
    "        contingency_table[0, 0] += 1  # Both correct\n",
    "    elif random_search_correct and not pso_correct:\n",
    "        contingency_table[0, 1] += 1  # Random Search correct, PSO wrong\n",
    "    elif not random_search_correct and pso_correct:\n",
    "        contingency_table[1, 0] += 1  # Random Search wrong, PSO correct\n",
    "    else:\n",
    "        contingency_table[1, 1] += 1  # Both wrong\n",
    "\n",
    "# Apply McNemar's test\n",
    "result = mcnemar(contingency_table, exact=True)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nComparison of Random Search vs PSO-Optimized Model:\")\n",
    "print(f\"Random Search Test Accuracy: {test_acc_random:.4f}\")\n",
    "print(f\"PSO-Optimized Test Accuracy: {test_acc_pso:.4f}\")\n",
    "\n",
    "# McNemar's Test results\n",
    "print(\"\\nMcNemar's Test Result:\")\n",
    "print(f\"p-value: {result.pvalue:.5f}\")\n",
    "if result.pvalue < 0.05:\n",
    "    print(\"The improvement from PSO optimization is **statistically significant**.\")\n",
    "else:\n",
    "    print(\"No **statistically significant** improvement from PSO optimization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529d2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
